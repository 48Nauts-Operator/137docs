<!-- Auto-generated by Claude on 2025-06-02 06:15 -->

# Unicode Properties Documentation

This Python file contains auto-generated Unicode property definitions for word break analysis based on Unicode version 13.0.0.

## Purpose

This module provides Unicode character property mappings used for word segmentation and text boundary detection. It defines character classes according to the Unicode Word Break algorithm (UAX #29), which is essential for:

- Text processing and parsing
- Word boundary detection
- Text tokenization
- Natural language processing applications

## Important Data Structures

### `unicode_word_break: dict[str, str]`

A comprehensive dictionary mapping Unicode word break property names to character ranges in string format. This covers the full Unicode character set.

**Key Properties Include:**

- **`aletter`**: Alphabetic characters (letters)
- **`numeric`**: Numeric characters (digits)
- **`cr`**: Carriage return character (`\r`)
- **`lf`**: Line feed character (`\n`)
- **`newline`**: Various newline characters
- **`extend`**: Extending characters (combining marks, etc.)
- **`format`**: Format control characters
- **`katakana`**: Katakana characters
- **`hebrewletter`**: Hebrew letters
- **`midletter`**: Mid-letter punctuation (like apostrophes in contractions)
- **`midnum`**: Mid-numeric punctuation (like commas in numbers)
- **`extendnumlet`**: Characters that extend alphanumeric sequences (like underscores)

**Negated Properties:**
Properties prefixed with `^` represent the complement (negation) of the base property.

### `ascii_word_break: dict[str, str]`

A simplified version containing only ASCII character mappings. This is useful for:
- Performance optimization when processing ASCII-only text
- Fallback scenarios
- Reduced memory usage applications

## Character Range Format

Character ranges are encoded as strings using Unicode escape sequences:
- `\x00-\x40`: ASCII range from null to '@'
- `\u0300-\u036f`: Unicode combining diacritical marks
- `\U00010000-\U0001000b`: Extended Unicode planes

## Usage Notes

### Important Considerations

1. **Auto-generated Content**: This file is automatically generated - do not manually edit
2. **Unicode Version**: Based on Unicode 13.0.0 - may need updates for newer Unicode versions
3. **Performance**: The `ascii_word_break` dictionary should be preferred for ASCII-only text processing
4. **Memory Usage**: The full Unicode mappings are quite large - consider lazy loading if memory is constrained

### Example Usage Patterns

```python
# Check if a character is alphabetic
if char in unicode_word_break['aletter']:
    # Handle alphabetic character
    pass

# Check if character is NOT numeric (using negated property)
if char in unicode_word_break['^numeric']:
    # Handle non-numeric character
    pass

# Use ASCII version for performance
if is_ascii_text:
    properties = ascii_word_break
else:
    properties = unicode_word_break
```

### Integration Suggestions

- Use with regex libraries for word boundary detection
- Integrate with tokenization pipelines
- Combine with text normalization processes
- Consider caching compiled regex patterns for frequently used properties

## Maintenance Notes

- Regenerate when updating to newer Unicode versions
- Test with diverse language samples after updates
- Monitor performance impact of large character class lookups
- Consider splitting into smaller modules if memory usage becomes problematic