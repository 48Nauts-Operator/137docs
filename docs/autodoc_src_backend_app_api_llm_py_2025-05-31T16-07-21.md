<!--
This documentation was auto-generated by Claude on 2025-05-31T16-07-21.
Source file: ./src/backend/app/api/llm.py
-->

# LLM API Router Documentation

## Overview

This module provides a FastAPI router for managing Large Language Model (LLM) operations including configuration management, document processing, tenant extraction, and batch operations. The router handles both synchronous and asynchronous LLM operations with proper error handling and logging.

## Dependencies

- **FastAPI**: Web framework and routing
- **SQLAlchemy**: Database operations with async support
- **Custom Services**: LLM service factory, document repository, tenant extraction
- **Authentication**: User authentication and authorization

## Configuration Endpoints

### GET `/config`

Retrieves the current LLM configuration settings.

**Parameters:**
- `db: AsyncSession` - Database session dependency

**Returns:**
```json
{
  "config": {
    "provider": "string",
    "api_key": "string",
    "api_url": "string",
    "model_tagger": "string",
    "model_enricher": "string",
    "enabled": "boolean"
  }
}
```

**Behavior:**
- Creates default configuration if none exists
- Returns complete configuration object

### PUT `/config`

Updates LLM configuration with form data.

**Parameters:**
- `request: Request` - Form data containing configuration fields
- `db: AsyncSession` - Database session dependency

**Form Fields:**
- **Provider Settings:**
  - `provider`: LLM provider name
  - `api_key`: Authentication key
  - `api_url`: Provider API endpoint

- **Model Settings:**
  - `model_tagger`: Model for tagging operations
  - `model_enricher`: Model for enrichment operations
  - `model_analytics`: Model for analytics operations
  - `model_responder`: Model for response generation

- **Feature Flags:**
  - `enabled`: Enable/disable LLM features
  - `auto_tagging`: Automatic document tagging
  - `auto_enrichment`: Automatic content enrichment
  - `external_enrichment`: External data enrichment
  - `cache_responses`: Response caching

- **Performance Settings:**
  - `max_retries`: Maximum retry attempts (integer)
  - `retry_delay`: Delay between retries (integer)
  - `batch_size`: Batch processing size (integer)
  - `concurrent_tasks`: Concurrent task limit (integer)
  - `min_confidence_tagging`: Minimum confidence for tagging (float)
  - `min_confidence_entity`: Minimum confidence for entities (float)

- **Backup Settings:**
  - `backup_provider`: Fallback provider
  - `backup_model`: Fallback model

**Returns:**
```json
{
  "message": "LLM configuration updated successfully",
  "config": { /* updated configuration */ }
}
```

**Error Handling:**
- Validates numeric fields with try/catch
- Logs configuration errors
- Returns 500 status for update failures

### POST `/test-connection`

Tests connectivity to the specified LLM provider.

**Parameters:**
- `request: Request` - Form data with connection details
- `db: AsyncSession` - Database session dependency

**Form Fields:**
- `provider`: Provider to test (required)
- `api_url`: Provider endpoint URL
- `api_key`: Authentication credentials

**Returns:**
Connection test results from the LLM repository

**Error Handling:**
- Validates required provider field
- Returns 400 for missing provider
- Returns 500 for connection failures

## Document Processing Endpoints

### POST `/process-document/{document_id}`

Processes a single document using LLM services.

**Parameters:**
- `document_id: int` - Document identifier
- `force: bool = False` - Force reprocessing flag
- `db: AsyncSession` - Database session dependency

**Returns:**
Processing results from the LLM document service

**Error Handling:**
- Logs processing errors with document ID
- Returns 500 for processing failures

### POST `/batch-process`

Processes multiple documents in batch mode.

**Parameters:**
- `request: Request` - Form data with document IDs
- `db: AsyncSession` - Database session dependency

**Form Fields:**
- `document_ids`: Comma-separated list of document IDs
- `force`: Force reprocessing flag ("true"/"false")

**Processing Logic:**
1. Parses comma-separated document ID string
2. Validates and converts IDs to integers
3. Filters out empty or invalid IDs
4. Executes batch processing via LLM service

**Returns:**
Batch processing results with success/failure counts

**Error Handling:**
- Validates document ID format
- Returns 400 for invalid or missing IDs
- Returns 500 for batch processing failures

### POST `/enrich-field/{document_id}`

Enriches a specific field within a document.

**Parameters:**
- `document_id: int` - Target document identifier
- `request: Request` - Form data with field specification
- `db: AsyncSession` - Database session dependency

**Form Fields:**
- `field_name`: Name of the field to enrich (required)

**Returns:**
Field enrichment results

**Error Handling:**
- Validates required field name
- Returns 400 for missing field name
- Returns 500 for enrichment failures

## Status and Analysis Endpoints

### GET `/status`

Retrieves comprehensive LLM service status and configuration.

**Parameters:**
- `db: AsyncSession` - Database session dependency

**Returns:**
```json
{
  "enabled": "boolean",
  "provider": "string",
  "auto_tagging": "boolean",
  "auto_enrichment": "boolean",
  "models": {
    "tagger": "string",
    "enricher": "string",
    "analytics": "string",
    "responder": "string"
  },
  "performance": {
    "batch_size": "integer",
    "concurrent_tasks": "integer",
    "max_retries": "integer"
  }
}
```

### POST `/suggest-tags/{document_id}`

Generates tag suggestions for a document using LLM analysis.

**Parameters:**
- `document_id: int` - Document to analyze
- `db: AsyncSession` - Database session dependency

**Processing:**
1. Retrieves document from repository
2. Validates document existence
3. Analyzes content for tag suggestions

**Returns:**
```