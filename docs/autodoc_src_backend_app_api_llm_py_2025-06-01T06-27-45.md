<!--
This documentation was auto-generated by Claude on 2025-06-01T06-27-45.
Source file: ./src/backend/app/api/llm.py
-->

# LLM API Router Documentation

## Overview

This module provides FastAPI routes for managing Large Language Model (LLM) services, including configuration, document processing, and tenant extraction capabilities. The router handles both single document operations and batch processing for efficient document management.

## Dependencies

- **FastAPI**: Web framework and dependency injection
- **SQLAlchemy**: Async database operations
- **Custom Services**: LLM services, repositories, and agents
- **Authentication**: User authentication and authorization

## Configuration Endpoints

### GET `/config`

Retrieves the current LLM configuration settings.

**Response:**
```json
{
  "config": {
    "provider": "string",
    "api_key": "string",
    "enabled": "boolean",
    // ... other config fields
  }
}
```

**Behavior:**
- Returns existing configuration if found
- Creates default configuration if none exists
- No authentication required

### PUT `/config`

Updates LLM configuration settings via form data.

**Parameters:**
- **Provider Settings:**
  - `provider`: LLM provider name
  - `api_key`: API authentication key
  - `api_url`: Provider API endpoint URL

- **Model Settings:**
  - `model_tagger`: Model for document tagging
  - `model_enricher`: Model for content enrichment
  - `model_analytics`: Model for document analysis
  - `model_responder`: Model for response generation

- **Boolean Settings:**
  - `enabled`: Enable/disable LLM services
  - `auto_tagging`: Automatic document tagging
  - `auto_enrichment`: Automatic content enrichment
  - `external_enrichment`: External enrichment sources
  - `cache_responses`: Response caching

- **Numeric Settings:**
  - `max_retries`: Maximum retry attempts
  - `retry_delay`: Delay between retries
  - `batch_size`: Documents per batch
  - `concurrent_tasks`: Parallel processing limit
  - `min_confidence_tagging`: Minimum tagging confidence
  - `min_confidence_entity`: Minimum entity confidence

**Response:**
```json
{
  "message": "LLM configuration updated successfully",
  "config": { /* updated config */ }
}
```

**Error Handling:**
- Returns 500 on configuration update failure
- Logs errors for debugging

### POST `/test-connection`

Tests connectivity to the specified LLM provider.

**Form Parameters:**
- `provider` (required): LLM provider identifier
- `api_url`: Provider API endpoint
- `api_key`: Authentication key

**Response:**
```json
{
  "status": "success|error",
  "message": "Connection test result"
}
```

**Error Handling:**
- Returns 400 if provider is missing
- Returns 500 on connection test failure

## Document Processing Endpoints

### POST `/process-document/{document_id}`

Processes a single document with LLM services.

**Parameters:**
- `document_id` (path): Document identifier
- `force` (query, optional): Force reprocessing

**Response:**
```json
{
  "status": "success",
  "document_id": "integer",
  "processing_results": { /* processing details */ }
}
```

**Features:**
- Applies configured LLM models
- Supports forced reprocessing
- Comprehensive error handling

### POST `/batch-process`

Processes multiple documents simultaneously.

**Form Parameters:**
- `document_ids`: Comma-separated document IDs
- `force`: Force reprocessing flag

**Response:**
```json
{
  "status": "completed",
  "total": "integer",
  "processed": "integer",
  "failed": "integer",
  "results": [ /* processing results */ ]
}
```

**Error Handling:**
- Validates document ID format
- Returns 400 for invalid input
- Handles batch processing failures gracefully

### POST `/enrich-field/{document_id}`

Enriches a specific document field using LLM.

**Parameters:**
- `document_id` (path): Document identifier
- `field_name` (form): Field to enrich

**Response:**
```json
{
  "status": "success",
  "field_name": "string",
  "original_value": "string",
  "enriched_value": "string"
}
```

## Analysis and Intelligence Endpoints

### GET `/status`

Retrieves LLM service status and configuration summary.

**Response:**
```json
{
  "enabled": "boolean",
  "provider": "string",
  "auto_tagging": "boolean",
  "auto_enrichment": "boolean",
  "models": {
    "tagger": "string",
    "enricher": "string",
    "analytics": "string",
    "responder": "string"
  },
  "performance": {
    "batch_size": "integer",
    "concurrent_tasks": "integer",
    "max_retries": "integer"
  }
}
```

### POST `/suggest-tags/{document_id}`

Generates tag suggestions for a document using LLM.

**Parameters:**
- `document_id` (path): Document identifier

**Response:**
```json
{
  "document_id": "integer",
  "suggested_tags": ["tag1", "tag2", "tag3"],
  "status": "success"
}
```

**Error Handling:**
- Returns 404 if document not found
- Handles LLM service failures

### POST `/analyze/{document_id}`

Performs comprehensive document analysis using LLM.

**Parameters:**
- `document_id` (path): Document identifier

**Response:**
```json
{
  "document_id": "integer",
  "analysis": {
    "summary": "string",
    "key_points": ["point1", "point2"],
    "sentiment": "positive|neutral|negative",
    "entities": [ /* extracted entities */ ]
  },
  "status": "success"
}
```

## Tenant Management Endpoints

### POST `/extract-tenant/{document_id}`

Extracts tenant information and assigns to document.

**Parameters:**
- `document_id` (path): Document identifier
- `current_user` (dependency): Authenticated user

**Response:**
```json
{
  "