<!--
This documentation was auto-generated by Claude on 2025-05-31T16-04-11.
Source file: ./src/backend/app/colpali_embedder.py
-->

# ColPali Embedding Helper

A Python module that provides a singleton wrapper for the ColPali vision-language model, enabling efficient document image embedding with lazy model loading.

## Overview

This module encapsulates the ColPali model to ensure it's instantiated only once per process, which is crucial given the model's computational requirements. It provides both multi-vector patch embeddings and global pooled vectors for document page images.

## Features

- **Lazy Loading**: Heavy VLM model is loaded only when first needed
- **Singleton Pattern**: Ensures single model instance per process
- **Dual Embedding Types**: Returns both patch-level and document-level embeddings
- **Automatic Caching**: Models are downloaded from HuggingFace and cached locally
- **Flexible Configuration**: Environment variable support for containerized deployments

## Installation

```bash
pip install colpali-engine torch pillow
```

## Configuration

The module supports configuration through environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `COLPALI_MODEL` | `"vidore/colpali-v1.1"` | HuggingFace model identifier |
| `HF_LOCAL_ONLY` | `"0"` | Use only locally cached models (1 to enable) |

## API Reference

### ColPaliEmbedder

A singleton class that wraps the ColPali model for efficient embedding generation.

#### Constructor

```python
ColPaliEmbedder(model_name: str = _DEFAULT_MODEL, device: str = _DEVICE)
```

**Parameters:**
- `model_name` (str): HuggingFace model identifier
- `device` (str): Target device ("cuda" or "cpu", auto-detected by default)

#### Methods

##### embed_page()

```python
@torch.inference_mode()
def embed_page(page_image: Image.Image) -> Tuple[Sequence[float], Sequence[float]]
```

Generates embeddings for a document page image.

**Parameters:**
- `page_image` (PIL.Image.Image): Input page image in PIL format

**Returns:**
- `Tuple[Sequence[float], Sequence[float]]`: 
  - `multi_vectors`: Patch-level embeddings, shape (num_patches, dim) - typically (196, 128)
  - `global_vector`: Document-level pooled embedding, shape (dim,) - typically (128,)

**Example:**
```python
from PIL import Image

embedder = ColPaliEmbedder()
image = Image.open("document_page.jpg")
multi_vecs, global_vec = embedder.embed_page(image)
```

##### embed_text()

```python
@torch.inference_mode()
def embed_text(text: str) -> Sequence[float]
```

Generates embeddings for text queries.

**Parameters:**
- `text` (str): Input text query

**Returns:**
- `Sequence[float]`: Global text embedding, shape (128,)

**Example:**
```python
embedder = ColPaliEmbedder()
query_embedding = embedder.embed_text("What is the total revenue?")
```

### Utility Functions

#### get_colpali_embeddings()

```python
def get_colpali_embeddings(page_path: str | Path) -> Tuple[Sequence[float], Sequence[float]]
```

Convenience function that loads an image from file and generates embeddings.

**Parameters:**
- `page_path` (str | Path): Path to the image file

**Returns:**
- Same as `embed_page()`: tuple of (multi_vectors, global_vector)

**Example:**
```python
multi_vecs, global_vec = get_colpali_embeddings("document.png")
```

## Usage Examples

### Basic Usage

```python
from colpali_embedder import ColPaliEmbedder
from PIL import Image

# Initialize embedder (singleton)
embedder = ColPaliEmbedder()

# Process a document page
image = Image.open("invoice.jpg").convert("RGB")
multi_vectors, global_vector = embedder.embed_page(image)

# Process a text query
query_embedding = embedder.embed_text("Find the invoice total")

print(f"Multi-vector shape: {multi_vectors.shape}")  # e.g., (196, 128)
print(f"Global vector shape: {global_vector.shape}")   # e.g., (128,)
print(f"Query embedding shape: {query_embedding.shape}") # e.g., (128,)
```

### Batch Processing

```python
from pathlib import Path

embedder = ColPaliEmbedder()
document_paths = Path("documents/").glob("*.jpg")

embeddings = []
for doc_path in document_paths:
    multi_vecs, global_vec = get_colpali_embeddings(doc_path)
    embeddings.append({
        'path': doc_path,
        'multi_vectors': multi_vecs,
        'global_vector': global_vec
    })
```

### Environment Configuration

```bash
# Use a different model
export COLPALI_MODEL="custom/colpali-model"

# Enable local-only mode (requires pre-downloaded weights)
export HF_LOCAL_ONLY="1"

python your_script.py
```

## Technical Details

### Model Architecture

- **Base Model**: ColPali vision-language model from vidore/colpali-v1.1
- **Multi-Vector Output**: Patch-level embeddings for fine-grained retrieval
- **Global Vector**: Mean-pooled document embedding for efficient similarity search
- **Text Processing**: Query embedding generation for cross-modal retrieval

### Performance Considerations

- **Device Selection**: Automatically uses CUDA if available, falls back to CPU
- **Memory Optimization**: Uses `low_cpu_mem_usage=True` for efficient loading
- **Precision**: Uses `float16` on CPU, `bfloat16` on GPU for memory efficiency
- **Singleton Pattern**: Prevents multiple model instances in memory

### File System Cache

Models are automatically cached by HuggingFace Hub in:
```
~/.cache/huggingface/
```

## Dependencies

- `torch`: PyTorch framework
- `