<!--
This documentation was auto-generated by Claude on 2025-06-01T06-24-24.
Source file: ./src/backend/app/colpali_embedder.py
-->

# ColPali Embedding Helper

A Python module that provides a convenient wrapper around the ColPali vision-language model for generating embeddings from document page images and text queries.

## Overview

This module encapsulates the ColPali model loading and embedding generation process, implementing a singleton pattern to ensure the heavy VLM (Vision-Language Model) is instantiated only once per process. It returns both multi-vector patch embeddings and global pooled vectors for document page images.

## Features

- **Lazy Model Loading**: Models are loaded only when first needed
- **Singleton Pattern**: Ensures single model instance per process
- **Dual Embedding Types**: Supports both multi-vector and global embeddings
- **Cross-Modal**: Handles both image and text inputs
- **Device Flexibility**: Automatically selects CUDA or CPU
- **Configuration via Environment**: Docker-compose friendly configuration

## Installation

```bash
pip install colpali-engine torch pillow
```

The ColPali model will be automatically downloaded from HuggingFace on first run and cached in `~/.cache/huggingface/`.

## Configuration

The module supports configuration via environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `COLPALI_MODEL` | `vidore/colpali-v1.1` | HuggingFace model identifier |
| `HF_LOCAL_ONLY` | `0` | Set to `1` to use only locally cached models |

## API Reference

### ColPaliEmbedder

Main class that wraps the ColPali model functionality.

#### Constructor

```python
ColPaliEmbedder(model_name: str = _DEFAULT_MODEL, device: str = _DEVICE)
```

**Parameters:**
- `model_name` (str): HuggingFace model identifier
- `device` (str): Target device ('cuda' or 'cpu')

#### Methods

##### embed_page()

```python
@torch.inference_mode()
def embed_page(page_image: Image.Image) -> Tuple[Sequence[float], Sequence[float]]
```

Generates embeddings for a document page image.

**Parameters:**
- `page_image` (PIL.Image.Image): Input page image in PIL format

**Returns:**
- `Tuple[Sequence[float], Sequence[float]]`: A tuple containing:
  - `multi_vectors`: Multi-vector patch embeddings, shape (num_patches, dim) - typically (196, 128)
  - `global_vector`: Pooled document embedding, shape (dim,) - typically (128,)

**Example:**
```python
from PIL import Image

embedder = ColPaliEmbedder()
image = Image.open("document_page.jpg").convert("RGB")
multi_vecs, global_vec = embedder.embed_page(image)
```

##### embed_text()

```python
@torch.inference_mode()
def embed_text(text: str) -> Sequence[float]
```

Generates a global embedding for text queries.

**Parameters:**
- `text` (str): Input text query

**Returns:**
- `Sequence[float]`: 128-dimensional global embedding vector

**Example:**
```python
embedder = ColPaliEmbedder()
query_embedding = embedder.embed_text("What is the total revenue?")
```

### Convenience Functions

#### get_colpali_embeddings()

```python
def get_colpali_embeddings(page_path: str | Path) -> Tuple[Sequence[float], Sequence[float]]
```

Utility function that loads an image from file and generates embeddings.

**Parameters:**
- `page_path` (str | Path): Path to the image file

**Returns:**
- `Tuple[Sequence[float], Sequence[float]]`: Same as `embed_page()` method

**Example:**
```python
multi_vecs, global_vec = get_colpali_embeddings("path/to/document.png")
```

## Usage Examples

### Basic Usage

```python
from colpali_embedder import ColPaliEmbedder
from PIL import Image

# Initialize embedder (singleton - safe to call multiple times)
embedder = ColPaliEmbedder()

# Process a document page
page_image = Image.open("document.jpg").convert("RGB")
patch_embeddings, document_embedding = embedder.embed_page(page_image)

# Process a text query
query_embedding = embedder.embed_text("Find financial data")
```

### Using Environment Configuration

```bash
# Set custom model
export COLPALI_MODEL="custom/colpali-model"

# Use local files only (no downloads)
export HF_LOCAL_ONLY=1

python your_script.py
```

### Docker Compose Integration

```yaml
services:
  app:
    environment:
      - COLPALI_MODEL=vidore/colpali-v1.1
      - HF_LOCAL_ONLY=0
```

## Technical Details

### Model Architecture
- **Input**: RGB images and text queries
- **Output Dimensions**: 
  - Multi-vector: (196, 128) for typical document pages
  - Global vector: (128,) for both images and text
- **Precision**: float16 (CPU) / bfloat16 (GPU) for inference, float32 for output

### Memory Optimization
- Uses `low_cpu_mem_usage=True` for efficient loading
- Implements `@torch.inference_mode()` for reduced memory overhead
- Automatic device selection and tensor movement

### Singleton Implementation
The class uses a singleton pattern to prevent multiple model instances:
- Model loaded once per process
- Thread-safe initialization guard
- Persistent across multiple instantiations

## Dependencies

- `torch`: PyTorch framework
- `PIL`: Python Imaging Library
- `colpali-engine`: ColPali model wrapper
- `huggingface_hub`: Model downloading and caching

## Error Handling

The module handles common scenarios:
- Automatic fallback to CPU if CUDA unavailable
- Graceful handling of missing local files when `HF_LOCAL_ONLY=1`
- PIL image format conversion to RGB

## Performance Considerations

- First call incurs model loading overhead
- Subsequent calls are fast due to singleton pattern
- GPU usage recommended for better performance
-