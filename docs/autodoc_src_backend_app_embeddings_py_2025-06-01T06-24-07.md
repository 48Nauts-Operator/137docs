<!--
This documentation was auto-generated by Claude on 2025-06-01T06-24-07.
Source file: ./src/backend/app/embeddings.py
-->

# Embedding Service Module

## Overview

This module provides text embedding functionality using the Ollama API with a robust fallback mechanism for offline development environments. It generates 1536-dimensional float vectors for text input, which are compatible with pgvector database storage.

## Dependencies

```python
import hashlib, math, os, json, logging, httpx
from typing import List
from app.config import settings
```

## Configuration

| Variable | Default Value | Description |
|----------|---------------|-------------|
| `OLLAMA_BASE_URL` | `http://host.docker.internal:11434` | Base URL for the Ollama API service |

## Functions

### `get_embedding(text: str, model: str = "nomic-embed-text") -> List[float]`

Generates a 1536-dimensional embedding vector for the provided text using the Ollama embeddings API.

#### Parameters

- **text** (`str`): The input text to generate embeddings for
- **model** (`str`, optional): The embedding model to use. Defaults to `"nomic-embed-text"`

#### Returns

- **`List[float]`**: A list of 1536 floating-point numbers representing the text embedding

#### Behavior

1. **Primary Operation**: Makes an HTTP POST request to the Ollama embeddings endpoint
2. **Fallback Mechanism**: If the API is unreachable, generates a deterministic pseudo-random embedding based on the text's SHA-256 hash
3. **Dimension Compliance**: Ensures output is exactly 1536 dimensions for pgvector compatibility

#### Error Handling

- Uses a 10-second timeout for HTTP requests
- Logs warnings when falling back to hash-based embeddings
- Ensures identical input text produces identical fallback vectors

#### Example Usage

```python
# Basic usage
embedding = await get_embedding("Hello, world!")

# With custom model
embedding = await get_embedding("Hello, world!", model="custom-model")
```

## Implementation Details

### Fallback Algorithm

When the Ollama API is unavailable, the function:

1. Computes SHA-256 hash of the input text
2. Repeats hash bytes to reach required length (1536 values)
3. Scales byte values from [0, 255] to [-1.0, 1.0] range using formula: `(v/128.0) - 1.0`

### API Integration

- **Endpoint**: `{OLLAMA_BASE_URL}/api/embeddings`
- **Method**: POST
- **Payload**: `{"model": model, "prompt": text}`
- **Timeout**: 10 seconds

## Logging

The module uses Python's standard logging framework with logger name based on the module's `__name__`. Warning-level messages are logged when the API fallback is triggered.

## Error Scenarios

| Scenario | Behavior |
|----------|----------|
| Network timeout | Falls back to hash-based embedding |
| API server down | Falls back to hash-based embedding |
| Invalid response | Falls back to hash-based embedding |
| Malformed JSON | Falls back to hash-based embedding |

## Notes

- The fallback mechanism ensures the application remains functional during development without requiring a live Ollama instance
- Embedding dimensions are truncated to 1536 to maintain compatibility with pgvector
- The deterministic fallback ensures consistent behavior across multiple calls with identical input