<!--
This documentation was auto-generated by Claude on 2025-06-01T06-20-47.
Source file: ./src/backend/app/llm.py
-->

# LLM Integration Module Documentation

## Overview

The LLM integration module provides comprehensive services for interacting with various Large Language Model (LLM) APIs to perform document analysis, metadata extraction, and content enrichment. The module supports multiple providers including local Ollama instances, OpenAI, Anthropic, and custom LLM endpoints.

## Classes

### LLMService

Main service class for LLM interactions with configuration support and intelligent caching.

#### Constructor

```python
def __init__(self, db_session: Optional[AsyncSession] = None)
```

**Parameters:**
- `db_session` (Optional[AsyncSession]): Database session for configuration management

#### Core Configuration Methods

##### `async get_config() -> Dict[str, Any]`

Retrieves LLM configuration from database with 5-minute caching to optimize performance.

**Returns:**
- Dictionary containing configuration parameters including:
  - `provider`: LLM provider ('local', 'openai', 'anthropic', etc.)
  - `api_url`: API endpoint URL  
  - `api_key`: Authentication key
  - Model configurations for different tasks
  - Processing parameters and limits

**Fallback Behavior:**
Falls back to environment variables if database configuration is unavailable.

##### `async is_enabled() -> bool`

Checks if LLM features are enabled in the configuration.

##### `async is_configured() -> bool`

Validates if the LLM service has proper configuration for the selected provider.

#### Document Processing Methods

##### `async extract_metadata(text: str, *, max_attempts: Optional[int] = None, target_score: float = 0.6, task_type: str = 'enricher') -> Dict[str, Any]`

Extracts structured metadata from document text using iterative LLM calls with quality scoring.

**Parameters:**
- `text` (str): Document text content
- `max_attempts` (Optional[int]): Maximum retry attempts (default from config)
- `target_score` (float): Minimum completeness score (0.0-1.0)
- `task_type` (str): Task type for model selection

**Returns:**
Dictionary containing extracted metadata fields:
- `title`: Document title
- `document_type`: Type classification
- `sender`/`recipient`: Parties involved
- `document_date`/`due_date`: Important dates (ISO format)
- `amount`/`currency`: Financial information
- Address and contact details
- Custom tags and classifications

**Process:**
1. Makes LLM API call with structured prompt
2. Parses JSON response
3. Applies heuristic enrichment using regex patterns
4. Scores completeness against target
5. Retries with focused prompts for missing fields if needed

##### `async analyze_document(text: str) -> Dict[str, Any]`

Performs comprehensive document analysis using LLM.

**Parameters:**
- `text` (str): Document text content

**Returns:**
Dictionary containing:
- `summary`: Brief document summary
- `key_points`: Important information list
- `entities`: Named entities (people, organizations, locations)
- `sentiment`: Overall sentiment analysis
- `action_items`: Required actions or tasks

##### `async suggest_tags(text: str) -> List[str]`

Generates contextual tags for document categorization.

**Parameters:**
- `text` (str): Document text content

**Returns:**
List of suggested tags (3-5 relevant categories)

#### Provider Testing and Discovery

##### `async test_connection(provider: str, api_url: Optional[str] = None, api_key: Optional[str] = None) -> Dict[str, Any]`

Tests connectivity to LLM provider with detailed debugging information.

**Parameters:**
- `provider` (str): Provider type ('local', 'openai', etc.)
- `api_url` (Optional[str]): Override API URL
- `api_key` (Optional[str]): Override API key

**Returns:**
Dictionary containing:
- `status`: 'success' or 'error'
- `message`: Descriptive result message
- `available_models`: List of discovered models
- `debug_info`: Detailed testing information

#### Private Implementation Methods

##### `async _get_available_models(provider: str, api_url: str, api_key: Optional[str] = None) -> List[str]`

Discovers available models from the provider's API.

##### `async _query_llm(prompt: str, task_type: str = 'enricher') -> str`

Routes LLM queries to appropriate provider endpoints based on configuration.

##### `async _query_ollama_direct(prompt: str, api_url: str, model: str) -> str`

Handles direct communication with Ollama API instances.

##### `async _query_generic_llm_direct(prompt: str, api_url: str, api_key: Optional[str], model: str) -> str`

Manages OpenAI-compatible API communication for various providers.

#### Response Processing

##### `_parse_metadata_response(response: str) -> Dict[str, Any]`
##### `_parse_analysis_response(response: str) -> Dict[str, Any]`  
##### `_parse_tags_response(response: str) -> List[str]`

Parse structured data from LLM responses with JSON5 fallback support.

#### Prompt Engineering

##### `_create_metadata_extraction_prompt(text: str, missing_fields: List[str] = None) -> str`

Generates optimized prompts for metadata extraction with field-specific focus for retries.

**Key Features:**
- Enforces ISO date format (YYYY-MM-DD)
- Handles Swiss/EU invoice formats
- Dynamic field targeting for efficient retries
- Text truncation for token management

##### `_create_document_analysis_prompt(text: str) -> str`
##### `_create_tag_suggestion_prompt(text: str) -> str`

Generate task-specific prompts for analysis and tagging operations.

#### Heuristic Enhancement

##### `_heuristic_enrich(text: str, metadata: Dict[str, Any]) -> Dict[str, Any]`

Applies regex-based post-processing to fill common omissions from LLM responses.

**Enhanced Fields:**
- Email addresses and phone numbers
- Currency amounts and financial data
- Swiss/EU address blocks
- VAT information and tax rates
- Company identifiers