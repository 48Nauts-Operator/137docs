<!--
This documentation was auto-generated by Claude on 2025-05-31T16-08-52.
Source file: ./src/backend/app/services/llm_service.py
-->

# DocumentLLMService API Documentation

## Overview

The DocumentLLMService module provides a high-level interface for integrating Large Language Model (LLM) capabilities with document processing workflows. It enables automated metadata extraction, content analysis, tag suggestion, and batch processing of documents.

## Classes

### DocumentLLMService

High-level LLM service for document processing tasks.

#### Constructor

```python
def __init__(self, db_session: AsyncSession)
```

**Parameters:**
- `db_session` (AsyncSession): SQLAlchemy async database session for data operations

**Attributes:**
- `db_session`: Database session instance
- `llm_service`: Core LLM service instance
- `doc_repo`: Document repository for database operations

#### Methods

##### process_document

```python
async def process_document(document_id: int, force: bool = False) -> Dict[str, Any]
```

Process a single document with LLM capabilities including metadata extraction, tag suggestion, and content analysis.

**Parameters:**
- `document_id` (int): ID of the document to process
- `force` (bool, optional): Whether to force reprocessing if already processed. Default: `False`

**Returns:**
- `Dict[str, Any]`: Processing results containing:
  - `document_id`: The processed document ID
  - `status`: Processing status (`"success"`, `"error"`, `"skipped"`, `"processing"`)
  - `message`: Descriptive message about the processing result
  - `metadata` (optional): Extracted document metadata
  - `suggested_tags` (optional): AI-generated tags
  - `analysis` (optional): Document content analysis

**Example:**
```python
service = DocumentLLMService(db_session)
result = await service.process_document(123, force=True)
print(result["status"])  # "success"
```

##### batch_process_documents

```python
async def batch_process_documents(document_ids: List[int], force: bool = False) -> Dict[str, Any]
```

Process multiple documents concurrently with configurable batch size and concurrency limits.

**Parameters:**
- `document_ids` (List[int]): List of document IDs to process
- `force` (bool, optional): Force processing even if already processed. Default: `False`

**Returns:**
- `Dict[str, Any]`: Batch processing results containing:
  - `status`: Overall batch status
  - `total`: Total number of documents
  - `processed`: Number of successfully processed documents
  - `skipped`: Number of skipped documents
  - `errors`: Number of failed documents
  - `details`: List of individual processing results

**Example:**
```python
result = await service.batch_process_documents([1, 2, 3, 4, 5])
print(f"Processed: {result['processed']}/{result['total']}")
```

##### enrich_document_field

```python
async def enrich_document_field(document_id: int, field_name: str) -> Dict[str, Any]
```

Enrich a specific field of a document using targeted LLM extraction.

**Parameters:**
- `document_id` (int): ID of the document to enrich
- `field_name` (str): Name of the field to extract/enrich

**Returns:**
- `Dict[str, Any]`: Enrichment result containing:
  - `status`: Operation status
  - `field`: The enriched field name
  - `value`: Extracted field value
  - `message`: Result description

**Example:**
```python
result = await service.enrich_document_field(123, "invoice_number")
if result["status"] == "success":
    print(f"Invoice number: {result['value']}")
```

#### Private Methods

##### _update_document_metadata

```python
async def _update_document_metadata(document: Document, metadata: Dict[str, Any]) -> None
```

Internal method to update document fields with LLM-extracted metadata.

**Parameters:**
- `document` (Document): Document instance to update
- `metadata` (Dict[str, Any]): Extracted metadata dictionary

**Field Mapping:**
- `title` → document.title
- `document_type` → document.document_type
- `sender` → document.sender
- `recipient` → document.recipient
- `document_date` → document.document_date
- `due_date` → document.due_date
- `amount` → document.amount
- `currency` → document.currency
- `status` → document.status

##### _add_tags_to_document

```python
async def _add_tags_to_document(document_id: int, tags: List[str]) -> None
```

Internal method to add AI-suggested tags to a document with validation.

**Parameters:**
- `document_id` (int): Target document ID
- `tags` (List[str]): List of suggested tags to add

### LLMServiceFactory

Factory class for creating LLM service instances.

#### Static Methods

##### create_document_service

```python
@staticmethod
def create_document_service(db_session: AsyncSession) -> DocumentLLMService
```

Create a DocumentLLMService instance.

**Parameters:**
- `db_session` (AsyncSession): Database session

**Returns:**
- `DocumentLLMService`: Configured service instance

##### create_llm_service

```python
@staticmethod
def create_llm_service(db_session: AsyncSession) -> LLMService
```

Create a basic LLMService instance.

**Parameters:**
- `db_session` (AsyncSession): Database session

**Returns:**
- `LLMService`: Core LLM service instance

## Configuration

The service respects various configuration options retrieved from the LLM service:

- `auto_enrichment` (bool): Enable automatic metadata extraction
- `auto_tagging` (bool): Enable automatic tag suggestion
- `batch_size` (int): Number of documents per batch (default: 5)
- `concurrent_tasks` (int): Maximum concurrent processing tasks (default: 2)
- `min_confidence_tagging` (float): Minimum confidence for tag acceptance (default: 0.7)

## Error Handling

All methods include comprehensive error handling:

- Database errors are logged and rolled back
- LLM service