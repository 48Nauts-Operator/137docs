<!--
This documentation was auto-generated by Claude on 2025-06-01T06-29-16.
Source file: ./src/backend/app/services/llm_service.py
-->

# DocumentLLMService Module

## Overview

The DocumentLLMService module provides high-level document processing capabilities using Large Language Models (LLM). It serves as an integration layer between document management and AI-powered content analysis, offering features like metadata extraction, tag suggestion, content analysis, and batch processing.

## Classes

### DocumentLLMService

A high-level service class that handles document processing tasks using LLM capabilities.

#### Constructor

```python
def __init__(self, db_session: AsyncSession)
```

**Parameters:**
- `db_session` (AsyncSession): SQLAlchemy async database session for data operations

**Description:**
Initializes the service with a database session and creates instances of the underlying LLM service and document repository.

#### Methods

##### process_document

```python
async def process_document(document_id: int, force: bool = False) -> Dict[str, Any]
```

**Parameters:**
- `document_id` (int): Unique identifier of the document to process
- `force` (bool, optional): Whether to force reprocessing if document was already processed. Defaults to `False`

**Returns:**
- `Dict[str, Any]`: Processing results containing status, metadata, tags, and analysis

**Description:**
Processes a single document with LLM capabilities including:
- Metadata extraction (if auto-enrichment is enabled)
- Tag suggestion (if auto-tagging is enabled) 
- Content analysis
- Document status updates

**Example Response:**
```json
{
  "document_id": 123,
  "status": "success",
  "metadata": {...},
  "suggested_tags": ["invoice", "finance"],
  "analysis": {...},
  "message": "Document processed successfully"
}
```

##### batch_process_documents

```python
async def batch_process_documents(document_ids: List[int], force: bool = False) -> Dict[str, Any]
```

**Parameters:**
- `document_ids` (List[int]): List of document IDs to process
- `force` (bool, optional): Force processing even if already processed. Defaults to `False`

**Returns:**
- `Dict[str, Any]`: Batch processing results with aggregated statistics

**Description:**
Processes multiple documents in batches with configurable concurrency limits. Provides detailed statistics and per-document results.

**Example Response:**
```json
{
  "status": "success",
  "total": 10,
  "processed": 8,
  "skipped": 1,
  "errors": 1,
  "details": [...]
}
```

##### enrich_document_field

```python
async def enrich_document_field(document_id: int, field_name: str) -> Dict[str, Any]
```

**Parameters:**
- `document_id` (int): ID of the document to enrich
- `field_name` (str): Name of the specific field to enrich

**Returns:**
- `Dict[str, Any]`: Enrichment result with extracted field value

**Description:**
Enriches a specific field of a document using targeted LLM prompts. Useful for extracting specific information like dates, amounts, or other structured data.

**Example Response:**
```json
{
  "status": "success",
  "field": "due_date",
  "value": "2024-01-15",
  "message": "Successfully enriched due_date"
}
```

#### Private Methods

##### _update_document_metadata

```python
async def _update_document_metadata(document: Document, metadata: Dict[str, Any]) -> None
```

**Description:**
Updates document fields with extracted metadata. Maps LLM-extracted metadata to corresponding document model fields and commits changes to the database.

**Supported Fields:**
- title
- document_type
- sender
- recipient
- document_date
- due_date
- amount
- currency
- status

##### _add_tags_to_document

```python
async def _add_tags_to_document(document_id: int, tags: List[str]) -> None
```

**Description:**
Adds LLM-suggested tags to a document with basic validation and confidence filtering.

### LLMServiceFactory

A factory class for creating LLM service instances.

#### Static Methods

##### create_document_service

```python
@staticmethod
def create_document_service(db_session: AsyncSession) -> DocumentLLMService
```

**Parameters:**
- `db_session` (AsyncSession): Database session for the service

**Returns:**
- `DocumentLLMService`: Configured document LLM service instance

##### create_llm_service

```python
@staticmethod
def create_llm_service(db_session: AsyncSession) -> LLMService
```

**Parameters:**
- `db_session` (AsyncSession): Database session for the service

**Returns:**
- `LLMService`: Basic LLM service instance

## Configuration

The service respects various configuration options retrieved from the LLM service:

- `auto_enrichment` (bool): Enable automatic metadata extraction
- `auto_tagging` (bool): Enable automatic tag suggestion
- `batch_size` (int): Number of documents to process per batch (default: 5)
- `concurrent_tasks` (int): Maximum concurrent processing tasks (default: 2)
- `min_confidence_tagging` (float): Minimum confidence threshold for tag addition (default: 0.7)

## Error Handling

The service implements comprehensive error handling:

- **Document Not Found**: Returns error status when document ID doesn't exist
- **LLM Service Disabled**: Gracefully handles disabled LLM processing
- **Processing Exceptions**: Catches and logs processing errors with detailed messages
- **Database Errors**: Handles database transaction failures with rollback

## Logging

The module uses Python's logging framework with the logger name derived from the module. Key events logged include:

- Document processing start/completion
- Metadata updates
- Tag additions
- Error conditions with stack traces

## Dependencies

- `sqlalchemy.ext.asyncio`: Async database operations
- `app.llm.LLMService`: Core LLM processing capabilities
- `app.models.Document`: Document data model
- `app.repository.DocumentRepository`: Document data access layer
- `app.agents.tenant_agent.TenantExtractionAgent`: Tenant information extraction

## Usage Example

```