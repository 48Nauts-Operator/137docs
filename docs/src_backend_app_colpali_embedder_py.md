<!-- Auto-generated by Claude on 2025-06-01 10:12 -->

# ColPali Embedding Helper

This module provides a wrapper for the ColPali (Contextualized Late Interaction over Patches) model, which is a Vision-Language Model (VLM) designed for document retrieval and analysis. The module implements lazy loading to ensure the heavy model is instantiated only once per process.

## Purpose

The ColPali embedding helper enables:
- **Multi-vector embeddings**: Patch-level embeddings that capture fine-grained details of document images
- **Global embeddings**: Pooled document-level embeddings for efficient similarity search
- **Text query embeddings**: Convert text queries into embeddings for retrieval tasks
- **Efficient resource management**: Singleton pattern ensures model is loaded only once

## Model Information

- **Default Model**: `vidore/colpali-v1.1` from HuggingFace
- **Model Cache**: Downloads are cached in `~/.cache/huggingface/`
- **Device Support**: Automatically detects and uses CUDA if available, falls back to CPU

## Configuration

The module can be configured through environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `COLPALI_MODEL` | `vidore/colpali-v1.1` | HuggingFace model identifier |
| `HF_LOCAL_ONLY` | `0` | Set to `1` to use only locally cached models |

## Classes

### `ColPaliEmbedder`

A singleton wrapper class that manages the ColPali model and processor.

#### Key Features:
- **Singleton Pattern**: Ensures single model instance per process
- **Lazy Loading**: Model loads only when first accessed
- **Memory Efficient**: Uses optimized loading with low CPU memory usage
- **Mixed Precision**: Uses `float16` for CPU, `bfloat16` for GPU

#### Methods:

##### `embed_page(page_image: Image.Image) -> Tuple[Sequence[float], Sequence[float]]`

Generates embeddings for a document page image.

**Parameters:**
- `page_image`: PIL Image object in RGB format

**Returns:**
- `multi_vectors`: Patch-level embeddings, shape `(num_patches, dim)` - typically `(196, 128)`
- `global_vector`: Document-level pooled embedding, shape `(dim,)` - typically `(128,)`

**Example:**
```python
from PIL import Image
embedder = ColPaliEmbedder()
image = Image.open("document_page.png")
patches, global_emb = embedder.embed_page(image)
```

##### `embed_text(text: str) -> Sequence[float]`

Generates embeddings for text queries.

**Parameters:**
- `text`: Query string

**Returns:**
- `Sequence[float]`: 128-dimensional embedding vector

**Example:**
```python
embedder = ColPaliEmbedder()
query_embedding = embedder.embed_text("What is the total revenue?")
```

## Utility Functions

### `get_colpali_embeddings(page_path: str | Path) -> Tuple[Sequence[float], Sequence[float]]`

Convenience function that loads an image from disk and returns its embeddings.

**Parameters:**
- `page_path`: Path to image file (string or Path object)

**Returns:**
- Same as `embed_page()`: `(multi_vectors, global_vector)`

**Example:**
```python
patches, global_emb = get_colpali_embeddings("path/to/document.png")
```

## Dependencies

- `torch`: PyTorch for model inference
- `PIL`: Image processing
- `colpali-engine`: HuggingFace wrapper for ColPali model

## Usage Notes

### Memory Management
- The model uses mixed precision to reduce memory usage
- GPU memory requirements are significant for the VLM
- Consider batch processing for multiple images if memory allows

### Performance Considerations
- First run will download the model (~2-3GB)
- GPU inference is significantly faster than CPU
- The `@torch.inference_mode()` decorator disables gradient computation for faster inference

### Image Format
- Images are automatically converted to RGB format
- Supported formats: PNG, JPEG, and other PIL-compatible formats

## Example Usage

```python
from PIL import Image
from pathlib import Path

# Initialize embedder (singleton)
embedder = ColPaliEmbedder()

# Process a document page
image = Image.open("invoice.png")
patch_embeddings, doc_embedding = embedder.embed_page(image)

# Process a text query
query_embedding = embedder.embed_text("Find total amount")

# Use convenience function
patches, global_emb = get_colpali_embeddings(Path("document.pdf.png"))
```

## Notes and Suggestions

‚ö†Ô∏è **Resource Requirements**: This model requires significant GPU memory. Consider using a machine with at least 8GB VRAM for optimal performance.

üí° **Batch Processing**: For processing multiple images, consider implementing batch processing to improve efficiency.

üîß **Local Deployment**: Set `HF_LOCAL_ONLY=1` to prevent network calls after initial model download for air-gapped environments.

üìù **Image Quality**: Higher resolution images may provide better embeddings but will increase processing time and memory usage.