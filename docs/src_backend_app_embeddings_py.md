<!-- Auto-generated by Claude on 2025-06-01 10:12 -->

# Ollama Embeddings Module

## Overview

This module provides text embedding functionality using the Ollama API. It converts text into numerical vector representations that can be used for semantic search, similarity comparisons, and other machine learning tasks.

## Purpose

- Generate 1536-dimensional embedding vectors from text using Ollama's embedding models
- Provide offline fallback functionality for development environments
- Interface with external Ollama service for text-to-vector conversion

## Configuration

The module uses environment variables for configuration:

- `OLLAMA_BASE_URL`: Base URL for the Ollama service (defaults to `http://host.docker.internal:11434`)

## Functions

### `get_embedding(text: str, model: str = "nomic-embed-text") -> List[float]`

Generates a 1536-dimensional embedding vector for the provided text.

**Parameters:**
- `text` (str): The input text to embed
- `model` (str, optional): The embedding model to use. Defaults to "nomic-embed-text"

**Returns:**
- `List[float]`: A list of 1536 floating-point numbers representing the text embedding

**Behavior:**
1. **Primary Mode**: Makes an HTTP POST request to the Ollama embeddings API
2. **Fallback Mode**: If the API is unreachable, generates a deterministic pseudo-random vector based on the text's SHA-256 hash

#### API Request Details

```python
# Request payload
{
    "model": "nomic-embed-text",
    "prompt": "your text here"
}

# Expected response format
{
    "embedding": [0.1, -0.2, 0.3, ...]
}
```

#### Fallback Mechanism

When the Ollama service is unavailable, the function:
1. Computes SHA-256 hash of the input text
2. Repeats the hash bytes to reach 1536 dimensions
3. Normalizes values to the range [-1, 1]
4. Ensures identical text always produces the same fallback vector

## Dependencies

- `hashlib`: For generating deterministic fallback embeddings
- `math`: Mathematical operations
- `os`: Environment variable access
- `json`: JSON data handling
- `logging`: Error and warning logging
- `httpx`: Async HTTP client for API requests
- `typing`: Type hints

## Error Handling

- **Timeout**: HTTP requests have a 10-second timeout
- **Network Errors**: All exceptions are caught and logged as warnings
- **Graceful Degradation**: Falls back to hash-based embeddings to maintain pipeline functionality

## Usage Example

```python
# Get embedding for text
embedding = await get_embedding("Hello, world!")

# Use custom model
embedding = await get_embedding("Hello, world!", model="custom-embed-model")
```

## Notes and Suggestions

### ‚ö†Ô∏è Important Considerations

- **Vector Dimensions**: Embeddings are truncated to 1536 dimensions for pgvector compatibility
- **Fallback Quality**: Hash-based fallbacks are not semantically meaningful and should only be used for development
- **Network Dependency**: Production environments should ensure Ollama service availability

### üîß Potential Improvements

1. **Configuration**: Consider making the embedding dimension configurable
2. **Caching**: Add embedding caching to reduce API calls for repeated text
3. **Model Validation**: Validate that the specified model exists before making requests
4. **Retry Logic**: Implement exponential backoff for transient network failures
5. **Metrics**: Add performance monitoring for embedding generation times

### üêõ Edge Cases

- Empty or very short text inputs may produce suboptimal embeddings
- Very long text may need chunking or truncation before embedding
- The fallback method doesn't preserve semantic relationships between different texts