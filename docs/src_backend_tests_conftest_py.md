<!-- Auto-generated by Claude on 2025-06-01 10:12 -->

# conftest.py - Pytest Configuration

## Overview

This file contains the pytest configuration and fixtures for the 137Docs backend test suite. It provides essential testing infrastructure including database setup, HTTP client configuration, and mock data fixtures for comprehensive testing of the application.

## Purpose

- **Test Environment Setup**: Configures isolated test environment with in-memory database
- **Fixture Management**: Provides reusable test fixtures for database sessions, HTTP clients, and mock data
- **Test Isolation**: Ensures tests run independently without affecting each other or production data
- **Mock Configuration**: Supplies mock LLM configurations and sample data for testing AI features

## Key Fixtures

### Database Fixtures

#### `event_loop` (Session Scope)
```python
@pytest.fixture(scope="session")
def event_loop():
```
- **Purpose**: Creates a single event loop for the entire test session
- **Scope**: Session-wide to ensure consistent async behavior across all tests
- **Note**: Essential for async database operations and HTTP requests

#### `test_engine` (Session Scope)
```python
@pytest.fixture(scope="session")
async def test_engine():
```
- **Purpose**: Creates an async SQLAlchemy engine for testing
- **Database**: Uses in-memory SQLite (`sqlite+aiosqlite:///:memory:`)
- **Features**:
  - Automatically creates all database tables
  - Cleans up engine resources after tests
  - Fast execution due to in-memory storage

#### `test_session`
```python
@pytest.fixture
async def test_session(test_engine):
```
- **Purpose**: Provides isolated database sessions for each test
- **Isolation**: Rolls back transactions after each test
- **Configuration**: 
  - `expire_on_commit=False` for better test performance
  - Automatic cleanup to prevent data leakage between tests

### HTTP Client Fixtures

#### `test_client`
```python
@pytest.fixture
async def test_client(test_session):
```
- **Purpose**: Creates an HTTP client for API endpoint testing
- **Features**:
  - Overrides database dependency with test session
  - Uses `httpx.AsyncClient` for async HTTP requests
  - Base URL set to `http://test`
  - Automatic cleanup of dependency overrides

### Mock Data Fixtures

#### `mock_llm_config`
```python
@pytest.fixture
def mock_llm_config():
```
- **Purpose**: Provides comprehensive LLM configuration for testing AI features
- **Configuration Options**:
  - **Provider**: Local deployment (`localhost:11434`)
  - **Models**: Different models for various tasks (tagging, enrichment, analytics, responses)
  - **Settings**: Retry logic, batch processing, confidence thresholds
  - **Features**: Auto-tagging, enrichment, caching enabled

#### `sample_document_text`
```python
@pytest.fixture
def sample_document_text():
```
- **Purpose**: Provides realistic document content for testing
- **Content**: Sample invoice with structured data including:
  - Company information
  - Dates and amounts
  - Tax calculations
  - Payment terms

#### `temp_file`
```python
@pytest.fixture
def temp_file():
```
- **Purpose**: Creates temporary files for file upload/processing tests
- **Features**:
  - Automatic cleanup after test completion
  - Configurable content and file extension
  - Safe file handling with proper resource management

## Configuration Details

### Database Configuration
```python
TEST_DATABASE_URL = "sqlite+aiosqlite:///:memory:"
```
- **Advantages**:
  - ‚úÖ Fast execution (in-memory)
  - ‚úÖ No cleanup required
  - ‚úÖ Isolated from production data
  - ‚úÖ Supports async operations

### LLM Configuration Highlights
```python
'model_tagger': 'phi3',           # Lightweight model for tagging
'model_enricher': 'llama3',       # Advanced model for enrichment
'model_responder': 'gpt-4',       # High-quality responses
'batch_size': 5,                  # Efficient batch processing
'min_confidence_tagging': 0.7,    # Quality thresholds
```

## Usage Examples

### Basic Test Structure
```python
async def test_create_document(test_client, sample_document_text):
    response = await test_client.post(
        "/documents/",
        json={"content": sample_document_text}
    )
    assert response.status_code == 201
```

### Database Test
```python
async def test_database_operation(test_session):
    # Perform database operations
    result = await test_session.execute(select(Document))
    documents = result.scalars().all()
    assert len(documents) == 0
```

### File Upload Test
```python
def test_file_processing(temp_file):
    with open(temp_file, 'r') as f:
        content = f.read()
    assert content == "Test document content"
```

## Notes and Recommendations

### ‚ö†Ô∏è Important Considerations

- **Import Dependencies**: Ensure `tests.test_models.Base` contains all your SQLAlchemy models
- **Async Handling**: All database and HTTP operations must use async/await
- **Resource Cleanup**: Fixtures automatically handle cleanup, but be mindful of external resources

### üîß Customization Suggestions

1. **Environment Variables**: Consider using environment variables for test configuration
2. **Database Variants**: Add fixtures for different database engines (PostgreSQL, MySQL)
3. **Authentication**: Add fixtures for user authentication and authorization testing
4. **File Types**: Extend `temp_file` fixture to support different file formats

### üöÄ Performance Tips

- Use session-scoped fixtures for expensive setup operations
- Consider parallel test execution with `pytest-xdist`
- Monitor test execution time and optimize slow fixtures

### üß™ Testing Best Practices

- Each test should be independent and idempotent
- Use descriptive fixture names that clearly indicate their purpose
- Group related fixtures and consider using `pytest.mark.parametrize` for multiple test cases